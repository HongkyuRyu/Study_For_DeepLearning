{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG16모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, ResNet50, ResNet50V2, Xception\n",
    "\n",
    "model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model:',  model)\n",
    "print('model output: ',  model.output) # 맨 마지막 layer가 출력된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretained 모델 기반으로 CIFAR 10 분류 모델 재 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "clear_session()\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "bm_output =  base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(bm_output)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block5_pool (MaxPooling2D)  : (None, 1, 1, 512) 이므로 1x1라서 성능이 떨어진다.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random as python_random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "def set_random_seed(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    python_random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "# 0~1사이의 값으로 변경\n",
    "def get_preprocessed_data(images, labels, scaling=True):\n",
    "    if scaling:\n",
    "        images = np.array(images/255.0, dtype=np.float32)\n",
    "    else:\n",
    "        images = np.array(images, dtype=np.float32)\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "    return images, labels\n",
    "\n",
    "# 0~1사이의 값을 받고, OHE적용\n",
    "def get_preprocessed_ohe(images, labels):\n",
    "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
    "    oh_labels = to_categorical(labels)\n",
    "    return images, oh_labels\n",
    "\n",
    "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE로 적용후 반환\n",
    "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2023):\n",
    "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
    "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
    "    \n",
    "    # 학습데이터를 학습데이터와 검증데이터로 분리\n",
    "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_labels, test_size=valid_size, random_state=random_state)\n",
    "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(2023)\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
    "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2023)\n",
    "print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImageDataGenerator로 Augmentation설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rescale=1/255.0\n",
    ")\n",
    "\n",
    "valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
    "flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(flow_tr_gen)\n",
    "print(image_batch.shape, label_batch.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import random as python_random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
    "def set_random_seed(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    python_random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
    "def get_preprocessed_data(images, labels, scaling=True):\n",
    "    \n",
    "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
    "    if scaling:\n",
    "        images = np.array(images/255.0, dtype=np.float32)\n",
    "    else:\n",
    "        images = np.array(images, dtype=np.float32)\n",
    "        \n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
    "def get_preprocessed_ohe(images, labels):\n",
    "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
    "    # OHE 적용 \n",
    "    oh_labels = to_categorical(labels)\n",
    "    return images, oh_labels\n",
    "\n",
    "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
    "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
    "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
    "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
    "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
    "    \n",
    "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
    "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
    "    \n",
    "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
    "\n",
    "# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음. \n",
    "# 마지막 feature map의 크기를 2로 만들기 위해 resize를 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨. \n",
    "def get_resized_images(images, resize=64):\n",
    "    image_cnt = images.shape[0] # 50k, 32, 32, 3\n",
    "    resized_images = np.zeros((images.shape[0], resize, resize, 3)) # 50k, 64, 64, 4\n",
    "    for i in range(image_cnt):\n",
    "        resized_image = cv2.resize(images[i], (resize, resize))\n",
    "        resized_images[i] = resized_image # 50k, 64, 64, 3\n",
    "    \n",
    "    return resized_images\n",
    "\n",
    "def create_model(model_name='vgg16', verbose=False):\n",
    "    \n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    if model_name == 'vgg16':\n",
    "        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'resnet50':\n",
    "        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'xception':\n",
    "        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    \n",
    "    bm_output = base_model.output\n",
    "\n",
    "    x = GlobalAveragePooling2D()(bm_output)\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(50, activation='relu', name='fc1')(x)\n",
    "    output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    model.summary()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def do_cifar10_train_evaluation(image_size=IMAGE_SIZE, model_name='vgg16'):\n",
    "    set_random_seed(2021)\n",
    "    # CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "    (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
    "        get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
    "    print('데이터 세트 shape:', tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n",
    "    \n",
    "    # 만약 image_size가 32보다 크면 이미지 크기 재조정. \n",
    "    if image_size > 32:\n",
    "        tr_images = get_resized_images(tr_images)\n",
    "        val_images = get_resized_images(val_images)\n",
    "        test_images = get_resized_images(test_images)\n",
    "    \n",
    "    # 학습/검증/테스트용 ImageDataGenerator와 flow로 pipeline 생성. \n",
    "    train_generator = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        rescale=1/255.0\n",
    "    )\n",
    "    valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "    test_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "    flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    flow_test_gen = train_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # model_name 에 따른 모델 생성하고 모델 학습 및 검증 수행. \n",
    "    model = create_model(model_name=model_name, verbose=True)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
    "    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
    "    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
    "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "    \n",
    "    tr_data_len = tr_images.shape[0]\n",
    "    val_data_len = val_images.shape[0]\n",
    "    history = model.fit(flow_tr_gen, epochs=40, \n",
    "                        steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n",
    "                        validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n",
    "                        callbacks=[rlr_cb, ely_cb])\n",
    "    # 테스트 데이터 세트로 모델 성능 검증 \n",
    "    evaluation_result = model.evaluate(flow_test_gen)\n",
    "    print('테스트 데이터 세트 evaluation 결과:', evaluation_result)\n",
    "    return history, evaluation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 shape: (42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 40s 0us/step\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 15, 15, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 15, 15, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 15, 15, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 13, 13, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 13, 13, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 13, 13, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 13, 13, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 13, 13, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 13, 13, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 7, 7, 128)    8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 7, 7, 128)    0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 128)    512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 7, 7, 128)    0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 7, 7, 128)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 7, 7, 256)    33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 7, 7, 256)    0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 7, 7, 256)    67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 4, 256)    32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4, 4, 256)    1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4, 4, 256)    0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 4, 4, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 4, 4, 728)    188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 4, 4, 728)    0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 2, 2, 728)    186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 2, 2, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2, 2, 728)    2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2, 2, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 2, 2, 728)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 2, 2, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 2, 2, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2, 2, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 2, 2, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 2, 2, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 2, 2, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2, 2, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 2, 2, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 2, 2, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 2, 2, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 2, 2, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 2, 2, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 2, 2, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 2, 2, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 2, 2, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 2, 2, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 2, 2, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 2, 2, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 2, 2, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 2, 2, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 2, 2, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 2, 2, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 2, 2, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 2, 2, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 2, 2, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 2, 2, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 2, 2, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1, 1, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 1, 1, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 1, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1, 1, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 1, 1, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 1, 1, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 1, 1, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 1, 1, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 1, 1, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 1, 1, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 50)           102450      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 10)           510         fc1[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 20,964,440\n",
      "Trainable params: 20,909,912\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minsu\\anaconda3\\envs\\hongkyu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 55s 74ms/step - loss: 0.7886 - accuracy: 0.7417 - val_loss: 0.4805 - val_accuracy: 0.8487\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 48s 72ms/step - loss: 0.4061 - accuracy: 0.8690 - val_loss: 0.5174 - val_accuracy: 0.8357\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 48s 72ms/step - loss: 0.3117 - accuracy: 0.9000 - val_loss: 0.4965 - val_accuracy: 0.8521\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 48s 72ms/step - loss: 0.2568 - accuracy: 0.9167 - val_loss: 0.5943 - val_accuracy: 0.8240\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 48s 72ms/step - loss: 0.2246 - accuracy: 0.9269 - val_loss: 0.3225 - val_accuracy: 0.8929\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 48s 72ms/step - loss: 0.1767 - accuracy: 0.9422 - val_loss: 0.3081 - val_accuracy: 0.9055\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.1507 - accuracy: 0.9506 - val_loss: 0.3737 - val_accuracy: 0.8832\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 49s 74ms/step - loss: 0.1337 - accuracy: 0.9561 - val_loss: 0.6476 - val_accuracy: 0.8461\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.1688 - accuracy: 0.9451 - val_loss: 0.3301 - val_accuracy: 0.9024\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 49s 73ms/step - loss: 0.1213 - accuracy: 0.9614 - val_loss: 0.6031 - val_accuracy: 0.8232\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 48s 72ms/step - loss: 0.1070 - accuracy: 0.9662 - val_loss: 0.3307 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.0383 - accuracy: 0.9873 - val_loss: 0.2434 - val_accuracy: 0.9363\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.2586 - val_accuracy: 0.9391\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.2888 - val_accuracy: 0.9348\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.2972 - val_accuracy: 0.9399\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 48s 72ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.3521 - val_accuracy: 0.9311\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.2925 - val_accuracy: 0.9389\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.2890 - val_accuracy: 0.9421\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.2908 - val_accuracy: 0.9437\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 48s 73ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.2967 - val_accuracy: 0.9440\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 49s 74ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.3060 - val_accuracy: 0.9421\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 49s 73ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.3181 - val_accuracy: 0.9427\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 00022: early stopping\n",
      "157/157 [==============================] - 4s 27ms/step - loss: 0.3598 - accuracy: 0.9339\n",
      "테스트 데이터 세트 evaluation 결과: [0.35979825258255005, 0.933899998664856]\n"
     ]
    }
   ],
   "source": [
    "history, evaluation_result = do_cifar10_train_evaluation(image_size=64, model_name='xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_history(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.xticks(np.arange(0, 30, 2))\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='valid')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hongkyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
